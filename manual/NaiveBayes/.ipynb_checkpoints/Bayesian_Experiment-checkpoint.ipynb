{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept\n",
    "The plain Bayesian classification model is a simple way to construct classifiers.The plain Bayesian classification model divides the problem into two categories, feature vectors and decision vectors, and assumes that the feature variables of the problem all act independently of each other on the decision variables, i.e., the features of the problem are all uncorrelated with each other. Despite this oversimplification assumption, the plain Bayesian classification model can exponentially reduce the complexity of Bayesian network construction, and also better handle the noise and irrelevant attributes of the training samples, so the plain Bayesian classification model still has efficient applications in many real-world problems, such as intrusion detection and text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Principle\n",
    "Bayesian theory originates from Bayes' theorem and Bayes' postulate proposed by Bayes. Bayes' theorem introduces the prior probability, and the posterior probability is calculated from the prior probability and the class of conditional probability expressions. Suppose there are random variables x and y，p(x，y) denotes their joint probability，p(x|y) and p(y|x) denote the conditional probability，where p(y|x) is the posterior probability, while p(y) is called the prior probability of y. The joint probability and conditional probability of x and y satisfy the following relationship：\n",
    "\n",
    "$p(y,x)=p(y|x)p(x)=p(x|y)p(y)$  \n",
    "\n",
    "After the exchange we get：\n",
    "\n",
    "$p(y|x)=\\frac{p(x|y)p(y)}{p(x)}$\n",
    "\n",
    "The above formula is Bayes' theorem, which provides a way to calculate the posterior probability p(y|x) from the prior probability p(y).\n",
    "\n",
    "Assuming that the characteristic vector of the problem is X = {x1, x2, ..., xn} and that X1, X2, ..., Xn} are independent of each other, then p(x|y) can be decomposed into the product of multiple vectors:\n",
    "\n",
    "$p(x|y)=\\prod_{i=1}^n p(x_i,y)$\n",
    "\n",
    "Then this problem can be solved by the plain Bayesian classifier: \n",
    "\n",
    "$p(y|x)=\\frac{p(y)\\prod_{i=1}^n p(x_i,y)}{p(x)}$\n",
    "\n",
    "where p(x) is a constant and the prior probability p(y) can be estimated by the proportion of samples from each class in the training set. Given Y = y, if the classification of test sample x is to be estimated, the posterior probability of y obtained from the plain Bayesian classification is：\n",
    "\n",
    "$p(y=Y|x)=\\frac{p(y=Y)\\prod_{i=1}^n p(x_i|y=Y)}{p(x)}$\n",
    "\n",
    "So finally it is enough to find the maximum class y of $p(y=Y)\\prod_{i=1}^n p(x_i|y=Y$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Plain Bayesian Module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "# The features of the custom test dataset x x have 4 dimensions\n",
    "x=np.array([[0,1,0,1],\n",
    "           [1,1,1,0],\n",
    "           [0,1,1,0],\n",
    "           [0,0,0,1],\n",
    "           [0,1,1,0],\n",
    "           [0,1,0,1],\n",
    "           [1,0,0,1]]\n",
    "          )\n",
    "# y is the label corresponding to x\n",
    "y=np.array([0,1,1,0,1,0,0])\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x,y)\n",
    "# Enter the next day into the model\n",
    "Next_Day=[[0,0,1,0]]\n",
    "pre=clf.predict(Next_Day)\n",
    "pre2=clf.predict_proba(Next_Day)\n",
    "# Output model prediction results\n",
    "print(\"prediction results：\",pre)\n",
    "# Output model predicted classification probabilities\n",
    "print(\"probabilities：\",pre2)\n",
    "# There are two predicted probability values which correspond to the probability that the categorization is 0 and 1.\n",
    "# The predicted result is the categorization with the higher probability value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example2\n",
    "Using the iris dataset in sklearn.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import the Plain Bayesian Module\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "muNB = GaussianNB()\n",
    "iris=load_iris()\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape  # Iris data type is 150*4 150 rows The 4 columns of each row represent the 4 characteristics of the iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Target values/label values for the Iris dataset：\\n', iris.target)\n",
    "print('Name of the Iris dataset features：\\n', iris.feature_names)\n",
    "print('Name of the target value of the Iris dataset：\\n', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two-dimensional data to see the distribution of the data\n",
    "for i in range(len(X)):\n",
    "    if y[i]==0:\n",
    "        plt.scatter([X[i][0]], [X[i][2]],c=\"r\")\n",
    "    elif y[i]==1:\n",
    "        plt.scatter([X[i][0]], [X[i][2]],c=\"g\")\n",
    "    else:\n",
    "        plt.scatter([X[i][0]], [X[i][2]],c=\"b\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split function is used to divide the data set, according to test_size=0.2, \n",
    "# 80% of the data will be divided into training set and 20% of the data will be divided into test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "muNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB.score(X_test, y_test) # Prediction Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please use the Bayesian model to train the load_breast_cancer dataset in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB = GaussianNB()\n",
    "breast=load_breast_cancer()\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB.score(X_test, y_test) # Prediction Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
