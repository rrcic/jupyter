{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Plain Bayesian Module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "# The features of the custom test dataset x x have 4 dimensions\n",
    "x=np.array([[0,1,0,1],\n",
    "           [1,1,1,0],\n",
    "           [0,1,1,0],\n",
    "           [0,0,0,1],\n",
    "           [0,1,1,0],\n",
    "           [0,1,0,1],\n",
    "           [1,0,0,1]]\n",
    "          )\n",
    "# y is the label corresponding to x\n",
    "y=np.array([0,1,1,0,1,0,0])\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x,y)\n",
    "# Enter the next day into the model\n",
    "Next_Day=[[0,0,1,0]]\n",
    "pre=clf.predict(Next_Day)\n",
    "pre2=clf.predict_proba(Next_Day)\n",
    "# Output model prediction results\n",
    "print(\"prediction results：\",pre)\n",
    "# Output model predicted classification probabilities\n",
    "print(\"probabilities：\",pre2)\n",
    "# There are two predicted probability values which correspond to the probability that the categorization is 0 and 1.\n",
    "# The predicted result is the categorization with the higher probability value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example2\n",
    "Using the iris dataset in sklearn.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import the Plain Bayesian Module\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "muNB = GaussianNB()\n",
    "iris=load_iris()\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape  # Iris data type is 150*4 150 rows The 4 columns of each row represent the 4 characteristics of the iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Target values/label values for the Iris dataset：\\n', iris.target)\n",
    "print('Name of the Iris dataset features：\\n', iris.feature_names)\n",
    "print('Name of the target value of the Iris dataset：\\n', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two-dimensional data to see the distribution of the data\n",
    "for i in range(len(X)):\n",
    "    if y[i]==0:\n",
    "        plt.scatter([X[i][0]], [X[i][2]],c=\"r\")\n",
    "    elif y[i]==1:\n",
    "        plt.scatter([X[i][0]], [X[i][2]],c=\"g\")\n",
    "    else:\n",
    "        plt.scatter([X[i][0]], [X[i][2]],c=\"b\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split function is used to divide the data set, according to test_size=0.2, \n",
    "# 80% of the data will be divided into training set and 20% of the data will be divided into test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "muNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB.score(X_test, y_test) # Prediction Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please use the Bayesian model to train the load_breast_cancer dataset in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB = GaussianNB()\n",
    "breast=load_breast_cancer()\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muNB.score(X_test, y_test) # Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
